# -*- coding: utf-8 -*-
"""House Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hJeyoOnMI4GwZfeANkEGCM7E2OSvvKSX
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("/content/Housing (1).csv")
df.head()

df.columns

import pandas as pd

# Example original columns list
cols = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad',
        'guestroom', 'basement', 'hotwaterheating', 'airconditioning',
        'parking', 'prefarea', 'furnishingstatus']

# Create a mapping from old column names to new pretty names
new_names = {
    'price': 'Price',
    'area': 'Area',
    'bedrooms': 'Bedrooms',
    'bathrooms': 'Bathrooms',
    'stories': 'Stories',
    'mainroad': 'Main Road',
    'guestroom': 'Guest Room',
    'basement': 'Basement',
    'hotwaterheating': 'Hot Water Heating',
    'airconditioning': 'Air Conditioning',
    'parking': 'Parking',
    'prefarea': 'Preferred Area',
    'furnishingstatus': 'Furnishing Status'
}

# Assuming your dataframe is called df, rename columns like this:
df.rename(columns=new_names, inplace=True)

df.head()

print(df.info())
print(df.describe())
print(df.shape)

df.isnull().sum()

binary_cols = ['Main Road', 'Guest Room', 'Basement', 'Hot Water Heating', 'Air Conditioning', 'Preferred Area']

for col in binary_cols:
    df[col] = df[col].map({'yes': 1, 'no': 0, 'Yes': 1, 'No': 0})

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Furnishing Status'] = le.fit_transform(df['Furnishing Status'])

df.head()

df.dtypes

# One-hot encode 'Furnishing Status' column
df = pd.get_dummies(df, columns=['Furnishing Status'], drop_first=True)

# Show new column names
print(df.columns)

import matplotlib.pyplot as plt
import seaborn as sns

# List of numerical columns including the target
num_cols = ['Price', 'Area', 'Bedrooms', 'Bathrooms', 'Stories', 'Parking']



# 2. Detect outliers using IQR method and print counts
for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]
    print(f"Number of outliers in '{col}': {outliers.shape[0]}")

total = len(df)
outlier_count = 15  # example for price
percentage = (outlier_count / total) * 100
print(f"{percentage:.2f}% outliers")

num_cols = ['Price', 'Area', 'Bedrooms', 'Bathrooms', 'Stories', 'Parking']
total = len(df)

for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    outlier_count = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)].shape[0]
    percentage = (outlier_count / total) * 100
    print(f"{col}: {outlier_count} outliers, {percentage:.2f}% of data")

def cap_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df[col] = df[col].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))

num_cols = ['Price', 'Area', 'Bedrooms', 'Bathrooms', 'Stories', 'Parking']

for col in num_cols:
    cap_outliers(df, col)

print("Outliers capped for selected numerical columns.")

num_cols = ['Price', 'Area', 'Bedrooms', 'Bathrooms', 'Stories', 'Parking']
total = len(df)

for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    outlier_count = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)].shape[0]
    percentage = (outlier_count / total) * 100
    print(f"{col}: {outlier_count} outliers, {percentage:.2f}% of data")

from sklearn.preprocessing import StandardScaler

# List of numerical columns to scale
num_cols = ['Area', 'Bedrooms', 'Bathrooms', 'Stories', 'Parking']  # update if needed

scaler = StandardScaler()

# Fit scaler on numerical columns and transform
df[num_cols] = scaler.fit_transform(df[num_cols])

print("Numerical columns scaled successfully.")

df.head()

X = df.drop('Price', axis=1)
y = df['Price']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

df.head()

# Example: one new data point (replace with actual values)
new_data = {
    'Area': 7420,
    'Bedrooms': 4,
    'Bathrooms': 2,
    'Stories': 3,
    'Main Road': 1,
    'Guest Room': 0,
    'Basement': 1,
    'Hot Water Heating': 0,
    'Air Conditioning': 1,
    'Parking': 2,
    'Preferred Area': 1, # Corrected column name: removed the extra tab
    # If you did one-hot encoding on furnishingstatus
    'Furnishing Status_1': 1,
    'Furnishing Status_2': 0,
}
import pandas as pd

new_df = pd.DataFrame([new_data])

# Reindex new_df to match the columns in X_train
# This ensures the columns are present and in the correct order
new_df = new_df.reindex(columns=X_train.columns, fill_value=0)

# Scale numerical columns using the previously fitted scaler
# Ensure num_cols contains the scaled numerical columns as they appear in X_train
scaled_cols_in_new_df = [col for col in num_cols if col in new_df.columns]
new_df[scaled_cols_in_new_df] = scaler.transform(new_df[scaled_cols_in_new_df])

predicted_price = model.predict(new_df)
print(f"Predicted House Price: {predicted_price[0]:.2f}")

